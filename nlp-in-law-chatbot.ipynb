{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01025da9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-24T16:47:19.044082Z",
     "iopub.status.busy": "2025-08-24T16:47:19.043069Z",
     "iopub.status.idle": "2025-08-24T16:47:23.085387Z",
     "shell.execute_reply": "2025-08-24T16:47:23.084311Z"
    },
    "papermill": {
     "duration": 4.048673,
     "end_time": "2025-08-24T16:47:23.087656",
     "exception": false,
     "start_time": "2025-08-24T16:47:19.038983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "#load datasets\n",
    "#Since these can be handled by builtin functions in pandas \n",
    "df_judgements = pd.read_csv(\"/kaggle/input/indian-supreme-court-judgments/judgments.csv\")\n",
    "df_acts = pd.read_excel(\"/kaggle/input/git-hub-dataset/MILPaC_Acts_dataset.xlsx\")\n",
    "df_faq = pd.read_excel(\"/kaggle/input/git-hub-dataset/MILPaC_CCI_FAQ_dataset.xlsx\")\n",
    "df_ip = pd.read_excel(\"/kaggle/input/git-hub-dataset/MILPaC_IP_dataset.xlsx\")\n",
    "\n",
    "# llm fine tuning dataset of indian legal texts requires json module to load since its files\n",
    "#are stored in json format\n",
    "# here def load_json is the function used for loading the json files in the container named data\n",
    "# which is then used to convert the data loaded to a dataframe using DataFrame function from the \n",
    "#pandas library\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df_constitution = load_json(\"/kaggle/input/llm-fine-tuning-dataset-of-indian-legal-texts/constitution_qa.json\")\n",
    "df_crpc = load_json(\"/kaggle/input/llm-fine-tuning-dataset-of-indian-legal-texts/crpc_qa.json\")\n",
    "df_ipc = load_json(\"/kaggle/input/llm-fine-tuning-dataset-of-indian-legal-texts/ipc_qa.json\")\n",
    "df_articles = load_json(\"/kaggle/input/git-hub-dataset/constitution_of_india.json\")\n",
    "df_legal_dataset = load_json(\"/kaggle/input/git-hub-dataset/IndicLegalQA Dataset_10K_Revised.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c342f6bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T16:47:23.094388Z",
     "iopub.status.busy": "2025-08-24T16:47:23.093876Z",
     "iopub.status.idle": "2025-08-24T16:47:23.138696Z",
     "shell.execute_reply": "2025-08-24T16:47:23.137877Z"
    },
    "papermill": {
     "duration": 0.050148,
     "end_time": "2025-08-24T16:47:23.140394",
     "exception": false,
     "start_time": "2025-08-24T16:47:23.090246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standardizes datasets with question naswer labels\n",
    "def standardize(df, q_col, a_col, source_name): \n",
    "    df_clean = df[[q_col, a_col]].dropna()\n",
    "    df_clean.columns = [\"question\", \"answer\"]\n",
    "    df_clean[\"source\"] = source_name\n",
    "    df_clean[\"intent\"] = \"law_info\"\n",
    "    return df_clean\n",
    "    \n",
    "# Standardizes datasets specifying articles, their titles and description \n",
    "def article_standardize(df):\n",
    "    df_clean = pd.DataFrame()\n",
    "    df_clean[\"question\"] = df.apply(\n",
    "        lambda row: f\"What does Article {row['article']} ({row['title']}) state?\", axis=1\n",
    "    )\n",
    "    df_clean[\"answer\"] = df[\"description\"]\n",
    "    df_clean[\"source\"] = \"Constitution\"\n",
    "    df_clean[\"intent\"] = \"law_info\"\n",
    "    return df_clean\n",
    "    \n",
    "#Standardizes translation dataset in ques and answer pairs\n",
    "def standardize_translation(df):\n",
    "    df_clean = pd.DataFrame()\n",
    "    df_clean[\"question\"] = df[\"src\"]\n",
    "    df_clean[\"answer\"]   = df[\"tgt\"]\n",
    "    df_clean[\"source\"]   = df[\"dataset\"]\n",
    "    \n",
    "    # If it's a translation dataset, intent can be \"translation\"\n",
    "    # Otherwise, adjust based on your use case\n",
    "    df_clean[\"intent\"]   = \"translation\"\n",
    "    return df_clean\n",
    "    \n",
    "#Standardizes the court cases in the form of QnA pairs to maintain consistency \n",
    "def standardize_cases(df):\n",
    "    df_clean = pd.DataFrame()\n",
    "    df_clean[\"question\"] = df[\"question\"]\n",
    "    df_clean[\"answer\"]   = df[\"answer\"]\n",
    "    df_clean[\"source\"]   = df[\"case_name\"] + \" (\" + df[\"judgement_date\"] + \")\"\n",
    "    df_clean[\"intent\"]   = \"case_info\"\n",
    "    return df_clean\n",
    "\n",
    "#Generalized llm data in the form of question answer format\n",
    "df_constitution_clean = standardize(df_constitution, \"question\", \"answer\", \"Constitution\")\n",
    "df_crpc_clean = standardize(df_crpc, \"question\", \"answer\", \"CrPC\")\n",
    "df_ipc_clean = standardize(df_ipc, \"question\", \"answer\", \"IPC\")\n",
    "\n",
    "#Articles of contitution converted to question answer format\n",
    "df_articles_clean = article_standardize(df_articles)\n",
    "\n",
    "#Question / Answers given in english as question and whose translations are given in \n",
    "#different regional languages as answers\n",
    "df_acts_clean = standardize_translation(df_acts)\n",
    "df_faq_clean = standardize_translation(df_faq)\n",
    "df_ip_clean = standardize_translation(df_ip)\n",
    "\n",
    "#Standardized court judgements\n",
    "df_legal_dataset_clean = standardize_cases(df_legal_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "076be702",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T16:47:23.145365Z",
     "iopub.status.busy": "2025-08-24T16:47:23.145081Z",
     "iopub.status.idle": "2025-08-24T16:47:24.343917Z",
     "shell.execute_reply": "2025-08-24T16:47:24.342996Z"
    },
    "papermill": {
     "duration": 1.203067,
     "end_time": "2025-08-24T16:47:24.345484",
     "exception": false,
     "start_time": "2025-08-24T16:47:23.142417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text): return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)   # remove extra spaces\n",
    "    text = re.sub(r\"[^\\w\\s.,?]\", \"\", text)  # remove special chars\n",
    "    return text.strip()\n",
    "\n",
    "for df in [df_constitution_clean, df_crpc_clean, df_ipc_clean,\n",
    "           df_acts_clean, df_faq_clean, df_ip_clean, df_articles_clean,df_legal_dataset_clean]:\n",
    "    df[\"question\"] = df[\"question\"].apply(clean_text)\n",
    "    df[\"answer\"] = df[\"answer\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e3cf41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T16:47:24.351917Z",
     "iopub.status.busy": "2025-08-24T16:47:24.350846Z",
     "iopub.status.idle": "2025-08-24T16:47:24.786045Z",
     "shell.execute_reply": "2025-08-24T16:47:24.784947Z"
    },
    "papermill": {
     "duration": 0.439981,
     "end_time": "2025-08-24T16:47:24.787760",
     "exception": false,
     "start_time": "2025-08-24T16:47:24.347779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = pd.concat([\n",
    "    df_constitution_clean, df_crpc_clean, df_ipc_clean,\n",
    "           df_acts_clean, df_faq_clean, df_ip_clean, df_articles_clean,df_legal_dataset_clean\n",
    "], ignore_index=True)\n",
    "\n",
    "# Shuffle & reset index\n",
    "df_final = df_final.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Save for chatbot\n",
    "df_final.to_csv(\"legal_chatbot_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48210801",
   "metadata": {
    "papermill": {
     "duration": 0.001849,
     "end_time": "2025-08-24T16:47:24.791852",
     "exception": false,
     "start_time": "2025-08-24T16:47:24.790003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13494422,
     "datasetId": 8129348,
     "sourceId": 12855460,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10617148,
     "datasetId": 2734042,
     "sourceId": 10312496,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 9239856,
     "datasetId": 5469366,
     "sourceId": 9068101,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.564712,
   "end_time": "2025-08-24T16:47:25.414170",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-24T16:47:13.849458",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
